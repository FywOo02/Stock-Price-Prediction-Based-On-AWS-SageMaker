{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "303ebdd1",
   "metadata": {},
   "source": [
    "### 1. Create a S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e698cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'yahoofinancestockpricedemo'\n",
    "try: \n",
    "    s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={'LocationConstraint': 'us-east-2'})\n",
    "    print('s3 bucket has been created')\n",
    "except Exception as e:\n",
    "    print('s3 error: ', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd8e8f2",
   "metadata": {},
   "source": [
    "### 2. Load the data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4523c741",
   "metadata": {},
   "source": [
    "#### i) install yahoo finance package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d43461",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c8f5bb",
   "metadata": {},
   "source": [
    "#### iiï¼‰import the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5ac53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# initial the orginal parameters\n",
    "start_date = datetime(2021, 1, 1)\n",
    "end_date = datetime(2023, 1, 1)\n",
    "\n",
    "# load the data\n",
    "data = yf.download('NVDA', start=start_date, end=end_date)\n",
    "data = data.reset_index()\n",
    "df_data = pd.DatafFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c90c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print data\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ef32be",
   "metadata": {},
   "source": [
    "### 3. Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3815b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Date and Adj Close\n",
    "df_data = df_data.drop(axis=1, columns=['Date'])\n",
    "df_data = df_data.drop(axis=1, columns=['Adj Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8732c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c34ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to take out a list of data as 'target', which indicates the next day 'Open'\n",
    "# get the processed data without the last day\n",
    "df_data_features = df_data.iloc[:-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a20adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7110ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the target list\n",
    "df_data_target = df_data.iloc[1:, 0].rename('Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ffff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2ee6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all the data together\n",
    "df_data_features['Target'] = list(df_data_target)\n",
    "move = df_data_features.pop('Target')\n",
    "df_data_features.insert(0, 'Target', move)\n",
    "df_data_final = df_data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0137d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e29e33b",
   "metadata": {},
   "source": [
    "### 4. Split train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3282d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# randomize the data set to make them be independent\n",
    "df_randomize = df_data_final.sample(frac=1, random_state=888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babf1e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_randomize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5fa2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data in to train set and test set\n",
    "train_data, test_data = np.split(df_randomize, [int(0.8*len(df_randomize))])\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb9a771",
   "metadata": {},
   "source": [
    "### 5. Set path and upload dataset to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23afa148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "prefix = 'xgboost-as-built-in-algorithm'\n",
    "train_path = 's3://{}/{}/{}/{}'.format(bucket_name, prefix, 'train', 'train.csv')\n",
    "test_path = 's3://{}/{}/{}/{}'.format(bucket_name, prefix, 'test', 'test.csv')\n",
    "print(train_path)\n",
    "print(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfa1262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data sets to S3 bucket\n",
    "train_data.to_csv(train_path, index=False, header = False)\n",
    "test_data.to_csv(test_path, index=False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859a27ce",
   "metadata": {},
   "source": [
    "### 6. Build up XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b25e8c",
   "metadata": {},
   "source": [
    "#### i) Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9678c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.inputs import TrainingInput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d0c7c6",
   "metadata": {},
   "source": [
    "#### ii) Find a XGBoost image URI and build up a XGBoost container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13ac5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "container = image_uris.retrieve('xgboost', boto3.Session().region_name, '1.2-2')\n",
    "display(container)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac9e1ae",
   "metadata": {},
   "source": [
    "#### iii) Initialize the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172d3205",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"reg:squarederror\",\n",
    "        \"early_stopping_rounds\":10,\n",
    "        \"num_round\":1000\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cadd49a",
   "metadata": {},
   "source": [
    "#### iv) Set an output path where the trained model will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc7fe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the output path in s3\n",
    "output_path = 's3://{}/{}/{}'.format(bucket_name, prefix, 'output')\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7e3b3d",
   "metadata": {},
   "source": [
    "#### v) Construct a Sagemaker Estimator to call the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7911cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(image_uri = container,\n",
    "                                         hyperparameters = hyperparameters,\n",
    "                                         role = sagemaker.get_execution_role(),\n",
    "                                         instance_count = 1,\n",
    "                                         instance_type = 'ml.m4.xlarge',\n",
    "                                         volum_size = 5,# 5 GB\n",
    "                                         output_path = output_path,\n",
    "                                         use_spot_instances = True,\n",
    "                                         max_run = 300,\n",
    "                                         max_wait = 600\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ce4781",
   "metadata": {},
   "source": [
    "#### vi) Define the data type and paths to the trainning and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95afd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_type = 'csv'\n",
    "train_input = TrainingInput('s3://{}/{}/{}'.format(bucket_name, prefix, 'train'), content_type = input_type)\n",
    "test_input = TrainingInput('s3://{}/{}/{}'.format(bucket_name, prefix, 'test'), content_type = input_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f2643a",
   "metadata": {},
   "source": [
    "#### vii) Execute the XGBoost trainning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "86d49a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2023-07-24-11-11-44-821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-24 11:11:44 Starting - Starting the training job...\n",
      "2023-07-24 11:12:10 Starting - Preparing the instances for training.........\n",
      "2023-07-24 11:13:41 Downloading - Downloading input data\n",
      "2023-07-24 11:13:41 Training - Downloading the training image......\n",
      "2023-07-24 11:14:32 Training - Training image download completed. Training in progress...\u001b[34m[2023-07-24 11:14:48.713 ip-10-0-130-131.us-east-2.compute.internal:6 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-07-24:11:14:48:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2023-07-24:11:14:48:INFO] Failed to parse hyperparameter objective value reg:squarederror to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2023-07-24:11:14:48:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2023-07-24:11:14:48:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2023-07-24:11:14:48:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2023-07-24:11:14:48:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2023-07-24:11:14:48:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2023-07-24:11:14:48:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2023-07-24:11:14:48:INFO] Single node training.\u001b[0m\n",
      "\u001b[34m[2023-07-24:11:14:48:INFO] Train matrix has 401 rows and 5 columns\u001b[0m\n",
      "\u001b[34m[2023-07-24:11:14:48:INFO] Validation matrix has 101 rows\u001b[0m\n",
      "\u001b[34m[2023-07-24 11:14:48.798 ip-10-0-130-131.us-east-2.compute.internal:6 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-07-24 11:14:48.798 ip-10-0-130-131.us-east-2.compute.internal:6 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-07-24 11:14:48.799 ip-10-0-130-131.us-east-2.compute.internal:6 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-07-24 11:14:48.799 ip-10-0-130-131.us-east-2.compute.internal:6 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-07-24 11:14:48.800 ip-10-0-130-131.us-east-2.compute.internal:6 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2023-07-24:11:14:48:INFO] Debug hook created from config\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:158.81126#011validation-rmse:159.14497\u001b[0m\n",
      "\u001b[34m[2023-07-24 11:14:48.898 ip-10-0-130-131.us-east-2.compute.internal:6 INFO hook.py:423] Monitoring the collections: metrics\u001b[0m\n",
      "\u001b[34m[2023-07-24 11:14:48.901 ip-10-0-130-131.us-east-2.compute.internal:6 INFO hook.py:486] Hook is writing from the hook with pid: 6\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:127.67036#011validation-rmse:128.24075\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:102.72191#011validation-rmse:103.44411\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:82.72091#011validation-rmse:83.42995\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:66.62048#011validation-rmse:67.45293\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:53.81840#011validation-rmse:54.63039\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:43.45113#011validation-rmse:44.33245\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:35.06067#011validation-rmse:35.99150\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:28.42494#011validation-rmse:29.37202\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:23.04609#011validation-rmse:24.17819\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:18.74669#011validation-rmse:20.01266\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:15.27992#011validation-rmse:16.56284\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:12.56021#011validation-rmse:13.89057\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:10.35466#011validation-rmse:11.77308\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:8.61890#011validation-rmse:10.13401\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:7.26368#011validation-rmse:8.92702\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:6.23542#011validation-rmse:7.98889\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:5.32310#011validation-rmse:7.17305\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:4.68869#011validation-rmse:6.65382\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:4.22161#011validation-rmse:6.26669\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:3.85935#011validation-rmse:5.98700\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:3.56047#011validation-rmse:5.80534\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:3.34728#011validation-rmse:5.70182\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:3.23135#011validation-rmse:5.61437\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:3.10865#011validation-rmse:5.53044\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:3.03349#011validation-rmse:5.51740\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:2.96607#011validation-rmse:5.50734\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:2.90156#011validation-rmse:5.50820\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:2.86233#011validation-rmse:5.49383\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:2.82084#011validation-rmse:5.48452\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:2.77801#011validation-rmse:5.48439\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:2.70825#011validation-rmse:5.47732\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:2.66905#011validation-rmse:5.46838\u001b[0m\n",
      "\u001b[34m[33]#011train-rmse:2.62739#011validation-rmse:5.50781\u001b[0m\n",
      "\u001b[34m[34]#011train-rmse:2.59481#011validation-rmse:5.50753\u001b[0m\n",
      "\u001b[34m[35]#011train-rmse:2.54907#011validation-rmse:5.51658\u001b[0m\n",
      "\u001b[34m[36]#011train-rmse:2.53198#011validation-rmse:5.50056\u001b[0m\n",
      "\u001b[34m[37]#011train-rmse:2.51371#011validation-rmse:5.50507\u001b[0m\n",
      "\u001b[34m[38]#011train-rmse:2.46018#011validation-rmse:5.49303\u001b[0m\n",
      "\u001b[34m[39]#011train-rmse:2.42392#011validation-rmse:5.50288\u001b[0m\n",
      "\u001b[34m[40]#011train-rmse:2.40501#011validation-rmse:5.53154\u001b[0m\n",
      "\u001b[34m[41]#011train-rmse:2.38662#011validation-rmse:5.53167\u001b[0m\n",
      "\u001b[34m[42]#011train-rmse:2.35454#011validation-rmse:5.51495\u001b[0m\n",
      "\n",
      "2023-07-24 11:15:08 Uploading - Uploading generated training model\n",
      "2023-07-24 11:15:08 Completed - Training job completed\n",
      "Training seconds: 112\n",
      "Billable seconds: 44\n",
      "Managed Spot Training savings: 60.7%\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train': train_input, 'validation': test_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a89ec0",
   "metadata": {},
   "source": [
    "#### viii) Deploy the trained xgboost model as endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "76dbf4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2023-07-24-11-16-07-124\n",
      "INFO:sagemaker:Creating endpoint-config with name sagemaker-xgboost-2023-07-24-11-16-07-124\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-xgboost-2023-07-24-11-16-07-124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "xgb_predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge', serializer=CSVSerializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "02a20855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-xgboost-2023-07-24-11-16-07-124'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_predictor.endpoint_name # show the name of endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43378737",
   "metadata": {},
   "source": [
    "#### ix) Make prediction with the use of Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bb399e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>447.309998</td>\n",
       "      <td>451.089996</td>\n",
       "      <td>440.400085</td>\n",
       "      <td>446.119995</td>\n",
       "      <td>36667890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Open        High         Low       Close    Volume\n",
       "0  447.309998  451.089996  440.400085  446.119995  36667890"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial parameters\n",
    "start = datetime(2023, 7, 25)\n",
    "end = datetime(2023, 7, 26)\n",
    "\n",
    "# get the data\n",
    "df_data = yf.download('NVDA', start=start, end=end)\n",
    "df_data = df_data.reset_index()\n",
    "\n",
    "## drop the feartures to lower dimensionality\n",
    "df_data = df_data.drop(axis=1, columns=['Adj Close'])\n",
    "df_data = df_data.drop(axis=1, columns = ['Date'])\n",
    "\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "51c713b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.47309998e+02, 4.51089996e+02, 4.40399994e+02, 4.46119995e+02,\n",
       "        3.82516000e+07]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_features_arr = df_data.values\n",
    "data_features_arr # show data array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fba474",
   "metadata": {},
   "source": [
    "### 7. Serialize data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850bd5ce",
   "metadata": {},
   "source": [
    "#### i) Inference - Serialized Input by Sagemaker Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2b660cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148.509995,149.960007,140.960007,143.149994,40127700.0 <class 'str'>\n",
      "143.09617614746094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "Serialized_Input_Data = CSVSerializer().serialize([[1.48509995e+02, 1.49960007e+02, 1.40960007e+02, 1.43149994e+02, 4.01277000e+07]])\n",
    "print(Serialized_Input_Data, type(Serialized_Input_Data))\n",
    "\n",
    "y_pred_func = xgb_predictor.predict(Serialized_Input_Data).decode('utf-8')\n",
    "print(y_pred_func) # show serialized output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbd23e0",
   "metadata": {},
   "source": [
    "#### ii) Inference - Serialized Input by built-in function(Lambda function friendly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5758f67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148.509995,149.960007,140.960007,143.149994,40127700.0\n",
      "148.509995,149.960007,140.960007,143.149994,40127700.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['143.09617614746094\\n', '143.09617614746094\\n']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Inputs = [[1.48509995e+02, 1.49960007e+02, 1.40960007e+02, 1.43149994e+02,\n",
    "        4.01277000e+07],\n",
    "        [1.48509995e+02, 1.49960007e+02, 1.40960007e+02, 1.43149994e+02,\n",
    "        4.01277000e+07]]\n",
    "y_pred = []\n",
    "for input in Inputs:\n",
    "    Serialized_Input = ','.join(map(str, input))\n",
    "    print(Serialized_Input)\n",
    "    y_pred.append(xgb_predictor.predict(Serialized_Input).decode('utf-8'))\n",
    "y_pred # show serialized output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441e0101",
   "metadata": {},
   "source": [
    "### 8. Create Lambda function handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e09f658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "ENDPOINT_NAME = 'sagemaker-xgboost-2023-07-24-11-16-07-124'\n",
    "runtime = boto3.client('runtime.sagemaker') # create a client to invoke the endpoint\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    inputs = event['data']\n",
    "    result = []\n",
    "    \n",
    "    for input in inputs:\n",
    "        Serialized_input = ','.join(map(str,input))\n",
    "        \n",
    "        response = runtime.invoke_endpoint(EndpointName = ENDPOINT_NAME,\n",
    "                                           ContentType = 'text/csv',\n",
    "                                           Body = Serialized_input)\n",
    "        \n",
    "        result.append(response['Body'].read().decode('utf-8')[:-1])\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8fc53055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['143.09617614746094', '143.09617614746094', '143.09617614746094']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input_json = {'data':[\n",
    "    [1.48509995e+02, 1.49960007e+02, 1.40960007e+02, 1.43149994e+02,4.01277000e+07],\n",
    "    [1.48509995e+02, 1.49960007e+02, 1.40960007e+02, 1.43149994e+02,4.01277000e+07],\n",
    "    [1.48509995e+02, 1.49960007e+02, 1.40960007e+02, 1.43149994e+02,4.01277000e+07]\n",
    "    ]\n",
    "}\n",
    "result = lambda_handler(Input_json, _)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
